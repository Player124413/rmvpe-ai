import gradio as gr
import os
import subprocess
import threading
import time
import re
import zipfile
import glob
import shutil
from pathlib import Path

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
training_log = []
is_training = False
current_process = None

def run_command(cmd, capture_output=True):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
    try:
        if capture_output:
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            return result.stdout + result.stderr
        else:
            os.system(cmd)
            return "–ö–æ–º–∞–Ω–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {str(e)}"

def setup_mute_files(mute_file):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ mute —Ñ–∞–π–ª–æ–≤"""
    os.chdir("/kaggle/working/rmvpe-ai")
    if mute_file == "spin_edition":
        run_command("rm -rf /kaggle/working/rmvpe-ai/logs/mute")
        run_command("mv /kaggle/working/rmvpe-ai/logs/mute_spin /kaggle/working/rmvpe-ai/logs/mute")
    elif mute_file == "spinv2_edition":
        run_command("rm -rf /kaggle/working/rmvpe-ai/logs/mute")
        run_command("mv /kaggle/working/rmvpe-ai/logs/mute_spin-v2 /kaggle/working/rmvpe-ai/logs/mute")
    return f"‚úì –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã mute —Ñ–∞–π–ª—ã: {mute_file}"

def setup_configs(configs, sample_rate):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥–æ–≤"""
    os.chdir("/kaggle/working/rmvpe-ai")
    if configs == "convbased_only_contentvec_48k":
        run_command("rm /kaggle/working/rmvpe-ai/configs/48k_v2.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/48k_convbased.json /kaggle/working/rmvpe-ai/configs/48k_v2.json")
    elif configs == "special_config_for_spinV2":
        run_command("rm /kaggle/working/rmvpe-ai/configs/48k_v2.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/48k_for_spin_v2.json /kaggle/working/rmvpe-ai/configs/48k_v2.json")
        run_command("rm /kaggle/working/rmvpe-ai/configs/40k.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/40k_for_spin_v2.json /kaggle/working/rmvpe-ai/configs/40k.json")
        run_command("rm /kaggle/working/rmvpe-ai/configs/32k_v2.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/32k_for_spin_v2.json /kaggle/working/rmvpe-ai/configs/32k_v2.json")
    return f"‚úì –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –∫–æ–Ω—Ñ–∏–≥–∏: {configs}"

def upload_dataset(files, dataset_name):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    dataset_path = f"dataset_raw/{dataset_name}"
    os.makedirs(dataset_path, exist_ok=True)
    
    for file in files:
        shutil.copy(file.name, dataset_path)
    
    return f"‚úì –î–∞—Ç–∞—Å–µ—Ç '{dataset_name}' –∑–∞–≥—Ä—É–∂–µ–Ω. –§–∞–π–ª–æ–≤: {len(files)}"

def preprocess_dataset(model_name, sample_rate, thread_count, progress=gr.Progress()):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    bitrate = int(sample_rate.rstrip("k")) * 1000
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    os.makedirs(f"logs/{model_name}", exist_ok=True)
    Path(f"logs/{model_name}/preprocess.log").touch()
    Path(f"logs/{model_name}/extract_f0_feature.log").touch()
    
    progress(0.3, desc="–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ...")
    result = run_command(f"python3 trainset_preprocess_pipeline_print.py /kaggle/working/rmvpe-ai/dataset_raw {bitrate} {thread_count} logs/{model_name} True")
    
    return f"‚úì –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n{result}"

def extract_features(model_name, thread_count, algo, machine_learning, progress=gr.Progress()):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    os.chdir("/kaggle/working/rmvpe-ai")
    
    progress(0.3, desc="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ F0...")
    run_command(f"python3 extract_f0_print.py logs/{model_name} {thread_count} {algo}")
    
    progress(0.7, desc="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    run_command(f"python3 extract_feature_print_{machine_learning}.py cuda 1 0 0 logs/{model_name} v2")
    
    return "‚úì –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"

def create_filelist(model_name, sample_rate):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–ª–∏—Å—Ç–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    run_command(f"python3 create_filelist_print.py {model_name} v2 True {sample_rate} 0")
    return "‚úì –§–∞–π–ª–ª–∏—Å—Ç —Å–æ–∑–¥–∞–Ω"

def create_index(model_name):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    run_command(f"python3 train_index_print.py {model_name} v2")
    return "‚úì –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω"

def start_training(model_name, sample_rate, vocoder, batch_size, epochs, save_interval, gpu, cache_data, only_latest, machine_learning):
    """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è"""
    global is_training, training_log, current_process
    
    os.chdir("/kaggle/working/rmvpe-ai")
    is_training = True
    training_log = []
    
    cmd = f"python3 train_nsf_sim_cache_sid_load_pretrain.py -e {model_name} -sr {sample_rate} -voc {vocoder} -f0 1 -bs {batch_size} -g {gpu} -te {epochs} -se {save_interval} -pg pretrained_v2/f0G{sample_rate}.pth -pd pretrained_v2/f0D{sample_rate}.pth -l {only_latest} -c {cache_data} -sw 1 -v v2"
    
    def run_training():
        global is_training
        os.system(cmd)
        is_training = False
    
    thread = threading.Thread(target=run_training)
    thread.start()
    
    return "üöÄ –û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ!"

def get_training_log(model_name):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
    log_file = f"/kaggle/working/rmvpe-ai/logs/{model_name}/train.log"
    if os.path.exists(log_file):
        with open(log_file, 'r') as f:
            lines = f.readlines()[-50:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å—Ç—Ä–æ–∫
            return "".join(lines)
    return "–õ–æ–≥–∏ –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã..."

def stop_training():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
    global is_training
    os.system("pkill -f train_nsf_sim_cache_sid_load_pretrain")
    is_training = False
    return "‚èπ –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"

def export_model(model_name, zip_name):
    """–≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏"""
    base_path = "/kaggle/working/rmvpe-ai"
    logs_dir = f"{base_path}/logs/{model_name}"
    weights_dir = f"{base_path}/weights"
    output_dir = "/kaggle/working/models"
    
    os.makedirs(output_dir, exist_ok=True)
    
    pth_file = f"{weights_dir}/{model_name}.pth"
    if not os.path.exists(pth_file):
        return "‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω", None
    
    index_files = glob.glob(f"{logs_dir}/added_IVF*_Flat_nprobe_1_{model_name}_v2.index")
    
    output_zip = f"{output_dir}/{zip_name}.zip"
    
    with zipfile.ZipFile(output_zip, 'w') as zipf:
        zipf.write(pth_file, f"{zip_name}.pth")
        for idx_file in index_files:
            ivf_num = idx_file.split('IVF')[1].split('_')[0]
            new_name = f"added_IVF{ivf_num}_Flat_nprobe_1_{zip_name}_v2.index"
            zipf.write(idx_file, new_name)
    
    return f"‚úì –ú–æ–¥–µ–ª—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞: {output_zip}", output_zip

# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ Gradio
with gr.Blocks(title="RVC Training WebUI", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üé§ RVC Training WebUI")
    gr.Markdown("–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π RVC")
    
    with gr.Tabs():
        # –í–∫–ª–∞–¥–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
        with gr.Tab("‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞"):
            gr.Markdown("### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            
            with gr.Row():
                with gr.Column():
                    vocoder = gr.Dropdown(
                        choices=["Hifi-GAN", "RefineGAN"],
                        value="Hifi-GAN",
                        label="–í–æ–∫–æ–¥–µ—Ä"
                    )
                    sample_rate = gr.Dropdown(
                        choices=["32k", "40k", "48k"],
                        value="32k",
                        label="Sample Rate"
                    )
                    mute_file = gr.Dropdown(
                        choices=["original", "spin_edition", "spinv2_edition"],
                        value="original",
                        label="Mute —Ñ–∞–π–ª—ã"
                    )
                    configs = gr.Dropdown(
                        choices=["original_for_all_sample_rates", "convbased_only_contentvec_48k", "special_config_for_spinV2"],
                        value="original_for_all_sample_rates",
                        label="–ö–æ–Ω—Ñ–∏–≥–∏"
                    )
        # –í–∫–ª–∞–¥–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        with gr.Tab("üìÅ –î–∞—Ç–∞—Å–µ—Ç"):
            gr.Markdown("### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
            
            with gr.Row():
                dataset_files = gr.File(
                    label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã",
                    file_count="multiple",
                    file_types=["audio"]
                )
                dataset_name = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞", value="my_dataset")
            
            upload_btn = gr.Button("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç", variant="primary")
            upload_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏")
            
            upload_btn.click(
                upload_dataset,
                inputs=[dataset_files, dataset_name],
                outputs=upload_output
            )
        
        # –í–∫–ª–∞–¥–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
        with gr.Tab("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞"):
            gr.Markdown("### –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            with gr.Row():
                with gr.Column():
                    model_name_prep = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏", value="mi-test")
                    sample_rate_prep = gr.Dropdown(choices=["32k", "40k", "48k"], value="32k", label="Sample Rate")
                    thread_count = gr.Slider(1, 16, value=8, step=1, label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤")
                
                with gr.Column():
                    algo = gr.Dropdown(
                        choices=["rmvpe_remake_exp", "rmvpe", "pm", "harvest", "crepe"],
                        value="rmvpe_remake_exp",
                        label="–ê–ª–≥–æ—Ä–∏—Ç–º F0"
                    )
                    ml_prep = gr.Dropdown(choices=["fairseq", "transformers"], value="fairseq", label="ML Backend")
            
            with gr.Row():
                preprocess_btn = gr.Button("1Ô∏è‚É£ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞", variant="secondary")
                extract_btn = gr.Button("2Ô∏è‚É£ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", variant="secondary")
                filelist_btn = gr.Button("3Ô∏è‚É£ –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª–ª–∏—Å—Ç", variant="secondary")
                index_btn = gr.Button("4Ô∏è‚É£ –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å", variant="secondary")
            
            all_prep_btn = gr.Button("üöÄ –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å—ë", variant="primary")
            prep_output = gr.Textbox(label="–õ–æ–≥ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏", lines=10)
            
            preprocess_btn.click(preprocess_dataset, inputs=[model_name_prep, sample_rate_prep, thread_count], outputs=prep_output)
            extract_btn.click(extract_features, inputs=[model_name_prep, thread_count, algo, ml_prep], outputs=prep_output)
            filelist_btn.click(create_filelist, inputs=[model_name_prep, sample_rate_prep], outputs=prep_output)
            index_btn.click(create_index, inputs=[model_name_prep], outputs=prep_output)
            
            def run_all_prep(mn, sr, tc, al, ml):
                logs = []
                logs.append(preprocess_dataset(mn, sr, tc))
                logs.append(extract_features(mn, tc, al, ml))
                logs.append(create_filelist(mn, sr))
                logs.append(create_index(mn))
                return "\n\n".join(logs)
            
            all_prep_btn.click(run_all_prep, inputs=[model_name_prep, sample_rate_prep, thread_count, algo, ml_prep], outputs=prep_output)
        
        # –í–∫–ª–∞–¥–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        with gr.Tab("üéØ –û–±—É—á–µ–Ω–∏–µ"):
            gr.Markdown("### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
            
            with gr.Row():
                with gr.Column():
                    model_name_train = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏", value="mi-test")
                    sample_rate_train = gr.Dropdown(choices=["32k", "40k", "48k"], value="32k", label="Sample Rate")
                    vocoder_train = gr.Dropdown(choices=["Hifi-GAN", "RefineGAN"], value="Hifi-GAN", label="–í–æ–∫–æ–¥–µ—Ä")
                    epochs = gr.Slider(1, 2000, value=300, step=1, label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö")
                    save_interval = gr.Slider(1, 500, value=100, step=1, label="–ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                
                with gr.Column():
                    batch_size = gr.Slider(1, 32, value=8, step=1, label="Batch Size")
                    gpu = gr.Textbox(label="GPU (0 –∏–ª–∏ 0,1)", value="0")
                    cache_data = gr.Checkbox(label="–ö—ç—à–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", value=False)
                    only_latest = gr.Checkbox(label="–¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Å–∞", value=False)
                    ml_train = gr.Dropdown(choices=["fairseq", "transformers"], value="fairseq", label="ML Backend")
            
            with gr.Row():
                train_btn = gr.Button("‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ", variant="primary")
                stop_btn = gr.Button("‚èπ –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å", variant="stop")
                refresh_log_btn = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –ª–æ–≥")
            
            train_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è", lines=2)
            train_log = gr.Textbox(label="–õ–æ–≥ –æ–±—É—á–µ–Ω–∏—è", lines=15)
            
            train_btn.click(
                start_training,
                inputs=[model_name_train, sample_rate_train, vocoder_train, batch_size, epochs, save_interval, gpu, cache_data, only_latest, ml_train],
                outputs=train_output
            )
            stop_btn.click(stop_training, outputs=train_output)
            refresh_log_btn.click(get_training_log, inputs=[model_name_train], outputs=train_log)
        
        # –í–∫–ª–∞–¥–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
        with gr.Tab("üì¶ –≠–∫—Å–ø–æ—Ä—Ç"):
            gr.Markdown("### –≠–∫—Å–ø–æ—Ä—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            
            with gr.Row():
                model_name_export = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (logs)", value="mi-test")
                zip_name = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ ZIP –∞—Ä—Ö–∏–≤–∞", value="my_model")
            
            export_btn = gr.Button("üì¶ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å", variant="primary")
            export_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å —ç–∫—Å–ø–æ—Ä—Ç–∞")
            download_file = gr.File(label="–°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å")
            
            export_btn.click(
                export_model,
                inputs=[model_name_export, zip_name],
                outputs=[export_output, download_file]
            )

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":

    demo.launch(share=True, server_name="0.0.0.0", server_port=7860)

