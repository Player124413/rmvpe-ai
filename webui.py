import gradio as gr
import os
import subprocess
import threading
import time
import re
import zipfile
import glob
import shutil
from pathlib import Path

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
training_log = []
is_training = False
current_process = None

def run_command(cmd, capture_output=True):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
    try:
        if capture_output:
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            return result.stdout + result.stderr
        else:
            os.system(cmd)
            return "–ö–æ–º–∞–Ω–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {str(e)}"

def install_dependencies(progress=gr.Progress()):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    progress(0, desc="–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã...")
    
    commands = [
        ("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ apt", "sudo apt-get update"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python 3.10", "sudo apt-get install -y python3.10"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ pip", "curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3.10 get-pip.py"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ uv", "pip install --no-cache-dir -q uv"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ protobuf", "uv pip install --no-cache-dir -q protobuf==3.20.3"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ setuptools", "uv pip install --no-cache-dir -q setuptools==57.5.0"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ aiohttp", "uv pip install --no-cache-dir -q aiohttp"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ wheel", "uv pip install --no-cache-dir -q wheel"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ ML –±–∏–±–ª–∏–æ—Ç–µ–∫", "uv pip install --no-cache-dir -q faiss-cpu==1.7.2 fairseq ffmpeg-python praat-parselmouth pyworld numpy==1.23.5 numba==0.56.4 librosa==0.9.2"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch", "uv pip install --no-cache-dir -q torch torchvision torchaudio"),
        ("–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è", "git clone https://github.com/Player124413/rmvpe-ai -b exp /kaggle/working/rmvpe-ai || true"),
        ("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ aria2", "apt-get -y install -qq aria2 || apt-get install --fix-missing"),
    ]
    
    log = []
    for i, (desc, cmd) in enumerate(commands):
        progress((i + 1) / len(commands), desc=desc)
        result = run_command(cmd)
        log.append(f"‚úì {desc}")
    
    return "\n".join(log)

def install_ml_requirements(machine_learning):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    os.chdir("/kaggle/working/rmvpe-ai")
    if machine_learning == "transformers":
        run_command("uv pip install --no-cache-dir -q -r requirements-transformers.txt")
    else:
        run_command("uv pip install --no-cache-dir -q -r requirements.txt")
    return f"‚úì –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è {machine_learning}"

def download_hubert(hubert_type):
    """–ó–∞–≥—Ä—É–∑–∫–∞ Hubert –º–æ–¥–µ–ª–∏"""
    os.chdir("/kaggle/working/rmvpe-ai")
    os.makedirs("Hubert", exist_ok=True)
    
    if hubert_type == "contentvec-fairseq":
        run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://bit.ly/4mmal7O -d /kaggle/working/rmvpe-ai/Hubert -o hubert_base.pt")
    elif hubert_type == "contentvec-transformers":
        run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://bit.ly/4mqQqVn -d /kaggle/working/rmvpe-ai/Hubert -o pytorch_model.bin")
        run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://bit.ly/3H7dRTq -d /kaggle/working/rmvpe-ai/Hubert -o config.json")
    elif hubert_type == "spin7-12-transformers":
        run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://bit.ly/4jccjoz -d /kaggle/working/rmvpe-ai/Hubert -o pytorch_model.bin")
        run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://bit.ly/436wyzh -d /kaggle/working/rmvpe-ai/Hubert -o config.json")
    elif hubert_type == "spinV2-transformers":
        run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/IAHispano/Applio/resolve/main/Resources/embedders/spin-v2/pytorch_model.bin -d /kaggle/working/rmvpe-ai/Hubert -o pytorch_model.bin")
        run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/IAHispano/Applio/resolve/main/Resources/embedders/spin-v2/config.json -d /kaggle/working/rmvpe-ai/Hubert -o config.json")
    
    return f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω Hubert: {hubert_type}"

def download_rmvpe():
    """–ó–∞–≥—Ä—É–∑–∫–∞ RMVPE –º–æ–¥–µ–ª–µ–π"""
    os.chdir("/kaggle/working/rmvpe-ai")
    run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://bit.ly/47Yxi9Y -d /kaggle/working/rmvpe-ai -o rmvpe.pt")
    run_command("aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/dr87/rmvpeV2/resolve/main/RMVPEV3_model_weights_298404.pt -d /kaggle/working/rmvpe-ai -o rmvpeV3.pt")
    return "‚úì –ó–∞–≥—Ä—É–∂–µ–Ω—ã RMVPE –∏ RMVPE V3"

def setup_mute_files(mute_file):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ mute —Ñ–∞–π–ª–æ–≤"""
    os.chdir("/kaggle/working/rmvpe-ai")
    if mute_file == "spin_edition":
        run_command("rm -rf /kaggle/working/rmvpe-ai/logs/mute")
        run_command("mv /kaggle/working/rmvpe-ai/logs/mute_spin /kaggle/working/rmvpe-ai/logs/mute")
    elif mute_file == "spinv2_edition":
        run_command("rm -rf /kaggle/working/rmvpe-ai/logs/mute")
        run_command("mv /kaggle/working/rmvpe-ai/logs/mute_spin-v2 /kaggle/working/rmvpe-ai/logs/mute")
    return f"‚úì –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã mute —Ñ–∞–π–ª—ã: {mute_file}"

def setup_configs(configs, sample_rate):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥–æ–≤"""
    os.chdir("/kaggle/working/rmvpe-ai")
    if configs == "convbased_only_contentvec_48k":
        run_command("rm /kaggle/working/rmvpe-ai/configs/48k_v2.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/48k_convbased.json /kaggle/working/rmvpe-ai/configs/48k_v2.json")
    elif configs == "special_config_for_spinV2":
        run_command("rm /kaggle/working/rmvpe-ai/configs/48k_v2.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/48k_for_spin_v2.json /kaggle/working/rmvpe-ai/configs/48k_v2.json")
        run_command("rm /kaggle/working/rmvpe-ai/configs/40k.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/40k_for_spin_v2.json /kaggle/working/rmvpe-ai/configs/40k.json")
        run_command("rm /kaggle/working/rmvpe-ai/configs/32k_v2.json")
        run_command("mv /kaggle/working/rmvpe-ai/configs/32k_for_spin_v2.json /kaggle/working/rmvpe-ai/configs/32k_v2.json")
    return f"‚úì –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –∫–æ–Ω—Ñ–∏–≥–∏: {configs}"

def download_pretrain(pretrain_type, sample_rate, use_hifigan, use_other):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ—Ç—Ä–µ–π–Ω–æ–≤"""
    os.chdir("/kaggle/working/rmvpe-ai")
    os.makedirs("pretrained_v2", exist_ok=True)
    
    log = []
    
    if use_hifigan:
        hugg_pret = "https://huggingface.co/Politrees/RVC_resources/resolve/main/pretrained/v2"
        pretrains = {
            "Default": [(f"{sample_rate}/Default/f0D{sample_rate}.pth", f"f0D{sample_rate}.pth"), 
                       (f"{sample_rate}/Default/f0G{sample_rate}.pth", f"f0G{sample_rate}.pth")],
            "¬ª Snowie v3": [(f"{sample_rate}/Snowie/D_SnowieV3.1_{sample_rate}.pth", f"f0D{sample_rate}.pth"), 
                           (f"{sample_rate}/Snowie/G_SnowieV3.1_{sample_rate}.pth", f"f0G{sample_rate}.pth")],
        }
        
        if pretrain_type in pretrains:
            for f in pretrains[pretrain_type]:
                run_command(f"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {hugg_pret}/{f[0]} -d /kaggle/working/rmvpe-ai/pretrained_v2 -o {f[1]}")
            log.append(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω HiFi-GAN –ø—Ä–µ—Ç—Ä–µ–π–Ω: {pretrain_type}")
    
    if use_other:
        other_pretrains_urls = {
            "legacyCorev2.5_contentvec": [
                ("https://huggingface.co/lyery/legacy-core-2.5/resolve/main/D_LSpeechV2.5.pth", "f0D32k.pth"),
                ("https://huggingface.co/lyery/legacy-core-2.5/resolve/main/G_LSpeechV2.5.pth", "f0G32k.pth")
            ],
            "spinV2pretrain_hifigan": [
                (f"https://huggingface.co/Aznamir/spin/resolve/main/spin-v2/f0D{sample_rate}_spin-v2.pth", f"f0D{sample_rate}.pth"),
                (f"https://huggingface.co/Aznamir/spin/resolve/main/spin-v2/f0G{sample_rate}_spin-v2.pth", f"f0G{sample_rate}.pth")
            ],
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–µ—Ç—Ä–µ–π–Ω—ã –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏
        log.append(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω –¥—Ä—É–≥–æ–π –ø—Ä–µ—Ç—Ä–µ–π–Ω")
    
    return "\n".join(log) if log else "–ü—Ä–µ—Ç—Ä–µ–π–Ω—ã –Ω–µ –≤—ã–±—Ä–∞–Ω—ã"

def upload_dataset(files, dataset_name):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    dataset_path = f"dataset_raw/{dataset_name}"
    os.makedirs(dataset_path, exist_ok=True)
    
    for file in files:
        shutil.copy(file.name, dataset_path)
    
    return f"‚úì –î–∞—Ç–∞—Å–µ—Ç '{dataset_name}' –∑–∞–≥—Ä—É–∂–µ–Ω. –§–∞–π–ª–æ–≤: {len(files)}"

def preprocess_dataset(model_name, sample_rate, thread_count, progress=gr.Progress()):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    bitrate = int(sample_rate.rstrip("k")) * 1000
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    os.makedirs(f"logs/{model_name}", exist_ok=True)
    Path(f"logs/{model_name}/preprocess.log").touch()
    Path(f"logs/{model_name}/extract_f0_feature.log").touch()
    
    progress(0.3, desc="–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ...")
    result = run_command(f"python3 trainset_preprocess_pipeline_print.py /kaggle/working/rmvpe-ai/dataset_raw {bitrate} {thread_count} logs/{model_name} True")
    
    return f"‚úì –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n{result}"

def extract_features(model_name, thread_count, algo, machine_learning, progress=gr.Progress()):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    os.chdir("/kaggle/working/rmvpe-ai")
    
    progress(0.3, desc="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ F0...")
    run_command(f"python3 extract_f0_print.py logs/{model_name} {thread_count} {algo}")
    
    progress(0.7, desc="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    run_command(f"python3 extract_feature_print_{machine_learning}.py cuda 1 0 0 logs/{model_name} v2")
    
    return "‚úì –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"

def create_filelist(model_name, sample_rate):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–ª–∏—Å—Ç–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    run_command(f"python3 create_filelist_print.py {model_name} v2 True {sample_rate} 0")
    return "‚úì –§–∞–π–ª–ª–∏—Å—Ç —Å–æ–∑–¥–∞–Ω"

def create_index(model_name):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞"""
    os.chdir("/kaggle/working/rmvpe-ai")
    run_command(f"python3 train_index_print.py {model_name} v2")
    return "‚úì –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω"

def start_training(model_name, sample_rate, vocoder, batch_size, epochs, save_interval, gpu, cache_data, only_latest, machine_learning):
    """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è"""
    global is_training, training_log, current_process
    
    os.chdir("/kaggle/working/rmvpe-ai")
    is_training = True
    training_log = []
    
    cmd = f"python3 train_nsf_sim_cache_sid_load_pretrain.py -e {model_name} -sr {sample_rate} -voc {vocoder} -f0 1 -bs {batch_size} -g {gpu} -te {epochs} -se {save_interval} -pg pretrained_v2/f0G{sample_rate}.pth -pd pretrained_v2/f0D{sample_rate}.pth -l {only_latest} -c {cache_data} -sw 1 -v v2"
    
    def run_training():
        global is_training
        os.system(cmd)
        is_training = False
    
    thread = threading.Thread(target=run_training)
    thread.start()
    
    return "üöÄ –û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ!"

def get_training_log(model_name):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
    log_file = f"/kaggle/working/rmvpe-ai/logs/{model_name}/train.log"
    if os.path.exists(log_file):
        with open(log_file, 'r') as f:
            lines = f.readlines()[-50:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å—Ç—Ä–æ–∫
            return "".join(lines)
    return "–õ–æ–≥–∏ –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã..."

def stop_training():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
    global is_training
    os.system("pkill -f train_nsf_sim_cache_sid_load_pretrain")
    is_training = False
    return "‚èπ –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"

def export_model(model_name, zip_name):
    """–≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏"""
    base_path = "/kaggle/working/rmvpe-ai"
    logs_dir = f"{base_path}/logs/{model_name}"
    weights_dir = f"{base_path}/weights"
    output_dir = "/kaggle/working/models"
    
    os.makedirs(output_dir, exist_ok=True)
    
    pth_file = f"{weights_dir}/{model_name}.pth"
    if not os.path.exists(pth_file):
        return "‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω", None
    
    index_files = glob.glob(f"{logs_dir}/added_IVF*_Flat_nprobe_1_{model_name}_v2.index")
    
    output_zip = f"{output_dir}/{zip_name}.zip"
    
    with zipfile.ZipFile(output_zip, 'w') as zipf:
        zipf.write(pth_file, f"{zip_name}.pth")
        for idx_file in index_files:
            ivf_num = idx_file.split('IVF')[1].split('_')[0]
            new_name = f"added_IVF{ivf_num}_Flat_nprobe_1_{zip_name}_v2.index"
            zipf.write(idx_file, new_name)
    
    return f"‚úì –ú–æ–¥–µ–ª—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞: {output_zip}", output_zip

# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ Gradio
with gr.Blocks(title="RVC Training WebUI", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üé§ RVC Training WebUI")
    gr.Markdown("–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π RVC")
    
    with gr.Tabs():
        # –í–∫–ª–∞–¥–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
        with gr.Tab("‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞"):
            gr.Markdown("### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            
            with gr.Row():
                with gr.Column():
                    machine_learning = gr.Dropdown(
                        choices=["fairseq", "transformers"],
                        value="fairseq",
                        label="–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"
                    )
                    vocoder = gr.Dropdown(
                        choices=["Hifi-GAN", "RefineGAN"],
                        value="Hifi-GAN",
                        label="–í–æ–∫–æ–¥–µ—Ä"
                    )
                    sample_rate = gr.Dropdown(
                        choices=["32k", "40k", "48k"],
                        value="32k",
                        label="Sample Rate"
                    )
                
                with gr.Column():
                    hubert = gr.Dropdown(
                        choices=["contentvec-fairseq", "contentvec-transformers", "spin7-12-transformers", "spinV2-transformers"],
                        value="contentvec-fairseq",
                        label="Hubert –º–æ–¥–µ–ª—å"
                    )
                    mute_file = gr.Dropdown(
                        choices=["original", "spin_edition", "spinv2_edition"],
                        value="original",
                        label="Mute —Ñ–∞–π–ª—ã"
                    )
                    configs = gr.Dropdown(
                        choices=["original_for_all_sample_rates", "convbased_only_contentvec_48k", "special_config_for_spinV2"],
                        value="original_for_all_sample_rates",
                        label="–ö–æ–Ω—Ñ–∏–≥–∏"
                    )
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### –ü—Ä–µ—Ç—Ä–µ–π–Ω—ã")
                    use_hifigan = gr.Checkbox(label="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HiFi-GAN –ø—Ä–µ—Ç—Ä–µ–π–Ω", value=False)
                    hifigan_pretrain = gr.Dropdown(
                        choices=["Default", "¬ª Snowie v3", "¬ª RIN_E3 - 40k", "¬ª Snowie - 40k", "¬ª Snowie + RIN_E3 - 40k", "¬ª Rigel - 32k", "¬ª Snowie v2 - 40k/48k", "¬ª Ov2Super - 40k", "¬ª TITAN-Medium"],
                        value="¬ª Snowie v3",
                        label="HiFi-GAN –ü—Ä–µ—Ç—Ä–µ–π–Ω"
                    )
                    use_other = gr.Checkbox(label="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π –ø—Ä–µ—Ç—Ä–µ–π–Ω", value=True)
                    other_pretrain = gr.Dropdown(
                        choices=["legacyCorev2.5_contentvec", "spinV2pretrain_hifigan", "spin7-12_pretrain-hifigan", "refinegan_pretrain-contentvec", "VocalCore"],
                        value="legacyCorev2.5_contentvec",
                        label="–î—Ä—É–≥–æ–π –ø—Ä–µ—Ç—Ä–µ–π–Ω"
                    )
            
            install_btn = gr.Button("üîß –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å—ë", variant="primary")
            install_output = gr.Textbox(label="–õ–æ–≥ —É—Å—Ç–∞–Ω–æ–≤–∫–∏", lines=10)
            
            def full_install(ml, voc, sr, hub, mute, conf, use_hifi, hifi_pre, use_oth, oth_pre):
                logs = []
                logs.append(install_dependencies())
                logs.append(install_ml_requirements(ml))
                logs.append(download_hubert(hub))
                logs.append(download_rmvpe())
                logs.append(setup_mute_files(mute))
                logs.append(setup_configs(conf, sr))
                logs.append(download_pretrain(hifi_pre, sr, use_hifi, use_oth))
                return "\n\n".join(logs)
            
            install_btn.click(
                full_install,
                inputs=[machine_learning, vocoder, sample_rate, hubert, mute_file, configs, use_hifigan, hifigan_pretrain, use_other, other_pretrain],
                outputs=install_output
            )
        
        # –í–∫–ª–∞–¥–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        with gr.Tab("üìÅ –î–∞—Ç–∞—Å–µ—Ç"):
            gr.Markdown("### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
            
            with gr.Row():
                dataset_files = gr.File(
                    label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã",
                    file_count="multiple",
                    file_types=["audio"]
                )
                dataset_name = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞", value="my_dataset")
            
            upload_btn = gr.Button("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç", variant="primary")
            upload_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏")
            
            upload_btn.click(
                upload_dataset,
                inputs=[dataset_files, dataset_name],
                outputs=upload_output
            )
        
        # –í–∫–ª–∞–¥–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
        with gr.Tab("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞"):
            gr.Markdown("### –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            with gr.Row():
                with gr.Column():
                    model_name_prep = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏", value="mi-test")
                    sample_rate_prep = gr.Dropdown(choices=["32k", "40k", "48k"], value="32k", label="Sample Rate")
                    thread_count = gr.Slider(1, 16, value=8, step=1, label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤")
                
                with gr.Column():
                    algo = gr.Dropdown(
                        choices=["rmvpe_remake_exp", "rmvpe", "pm", "harvest", "crepe"],
                        value="rmvpe_remake_exp",
                        label="–ê–ª–≥–æ—Ä–∏—Ç–º F0"
                    )
                    ml_prep = gr.Dropdown(choices=["fairseq", "transformers"], value="fairseq", label="ML Backend")
            
            with gr.Row():
                preprocess_btn = gr.Button("1Ô∏è‚É£ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞", variant="secondary")
                extract_btn = gr.Button("2Ô∏è‚É£ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", variant="secondary")
                filelist_btn = gr.Button("3Ô∏è‚É£ –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª–ª–∏—Å—Ç", variant="secondary")
                index_btn = gr.Button("4Ô∏è‚É£ –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å", variant="secondary")
            
            all_prep_btn = gr.Button("üöÄ –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å—ë", variant="primary")
            prep_output = gr.Textbox(label="–õ–æ–≥ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏", lines=10)
            
            preprocess_btn.click(preprocess_dataset, inputs=[model_name_prep, sample_rate_prep, thread_count], outputs=prep_output)
            extract_btn.click(extract_features, inputs=[model_name_prep, thread_count, algo, ml_prep], outputs=prep_output)
            filelist_btn.click(create_filelist, inputs=[model_name_prep, sample_rate_prep], outputs=prep_output)
            index_btn.click(create_index, inputs=[model_name_prep], outputs=prep_output)
            
            def run_all_prep(mn, sr, tc, al, ml):
                logs = []
                logs.append(preprocess_dataset(mn, sr, tc))
                logs.append(extract_features(mn, tc, al, ml))
                logs.append(create_filelist(mn, sr))
                logs.append(create_index(mn))
                return "\n\n".join(logs)
            
            all_prep_btn.click(run_all_prep, inputs=[model_name_prep, sample_rate_prep, thread_count, algo, ml_prep], outputs=prep_output)
        
        # –í–∫–ª–∞–¥–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        with gr.Tab("üéØ –û–±—É—á–µ–Ω–∏–µ"):
            gr.Markdown("### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
            
            with gr.Row():
                with gr.Column():
                    model_name_train = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏", value="mi-test")
                    sample_rate_train = gr.Dropdown(choices=["32k", "40k", "48k"], value="32k", label="Sample Rate")
                    vocoder_train = gr.Dropdown(choices=["Hifi-GAN", "RefineGAN"], value="Hifi-GAN", label="–í–æ–∫–æ–¥–µ—Ä")
                    epochs = gr.Slider(1, 2000, value=300, step=1, label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö")
                    save_interval = gr.Slider(1, 500, value=100, step=1, label="–ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                
                with gr.Column():
                    batch_size = gr.Slider(1, 32, value=8, step=1, label="Batch Size")
                    gpu = gr.Textbox(label="GPU (0 –∏–ª–∏ 0,1)", value="0")
                    cache_data = gr.Checkbox(label="–ö—ç—à–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", value=False)
                    only_latest = gr.Checkbox(label="–¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Å–∞", value=False)
                    ml_train = gr.Dropdown(choices=["fairseq", "transformers"], value="fairseq", label="ML Backend")
            
            with gr.Row():
                train_btn = gr.Button("‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ", variant="primary")
                stop_btn = gr.Button("‚èπ –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å", variant="stop")
                refresh_log_btn = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –ª–æ–≥")
            
            train_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è", lines=2)
            train_log = gr.Textbox(label="–õ–æ–≥ –æ–±—É—á–µ–Ω–∏—è", lines=15)
            
            train_btn.click(
                start_training,
                inputs=[model_name_train, sample_rate_train, vocoder_train, batch_size, epochs, save_interval, gpu, cache_data, only_latest, ml_train],
                outputs=train_output
            )
            stop_btn.click(stop_training, outputs=train_output)
            refresh_log_btn.click(get_training_log, inputs=[model_name_train], outputs=train_log)
        
        # –í–∫–ª–∞–¥–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
        with gr.Tab("üì¶ –≠–∫—Å–ø–æ—Ä—Ç"):
            gr.Markdown("### –≠–∫—Å–ø–æ—Ä—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            
            with gr.Row():
                model_name_export = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (logs)", value="mi-test")
                zip_name = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ ZIP –∞—Ä—Ö–∏–≤–∞", value="my_model")
            
            export_btn = gr.Button("üì¶ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å", variant="primary")
            export_output = gr.Textbox(label="–°—Ç–∞—Ç—É—Å —ç–∫—Å–ø–æ—Ä—Ç–∞")
            download_file = gr.File(label="–°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å")
            
            export_btn.click(
                export_model,
                inputs=[model_name_export, zip_name],
                outputs=[export_output, download_file]
            )

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    demo.launch(share=True, server_name="0.0.0.0", server_port=7860)